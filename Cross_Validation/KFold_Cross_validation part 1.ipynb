{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQs7t2SAlk7VTvpf+D0mrm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndraMadika/ML_Study/blob/main/Cross_Validation/KFold_Cross_validation%20part%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import legacy as legacy_optimizer\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Model configuration\n",
        "batch_size = 50\n",
        "img_width, img_height, img_num_channels = 32, 32, 3\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 100\n",
        "no_epochs = 5\n",
        "optimizer = legacy_optimizer.Adam()  # Menggunakan legacy optimizer\n",
        "verbosity = 1\n",
        "num_folds = 10\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n",
        "\n",
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n",
        "\n",
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((input_train, input_test), axis=0)\n",
        "targets = np.concatenate((target_train, target_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=loss_function,\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              verbose=verbosity)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRVmaYscDG33",
        "outputId": "5a89f28e-08a4-4ad6-be27-10fe8f3a975a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 77s 70ms/step - loss: 1.4887 - accuracy: 0.4684\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 72s 67ms/step - loss: 1.0776 - accuracy: 0.6236\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 78s 72ms/step - loss: 0.9109 - accuracy: 0.6809\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 79s 73ms/step - loss: 0.7963 - accuracy: 0.7224\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 77s 71ms/step - loss: 0.6958 - accuracy: 0.7587\n",
            "Score for fold 1: loss of 0.8648485541343689; accuracy of 70.45000195503235%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 75s 69ms/step - loss: 1.5537 - accuracy: 0.4360\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 76s 70ms/step - loss: 1.1713 - accuracy: 0.5829\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 78s 72ms/step - loss: 1.0278 - accuracy: 0.6387\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 72s 67ms/step - loss: 0.9313 - accuracy: 0.6739\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 70s 64ms/step - loss: 0.8532 - accuracy: 0.7010\n",
            "Score for fold 2: loss of 0.9767177700996399; accuracy of 64.98333215713501%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 1.5234 - accuracy: 0.4489\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 72s 66ms/step - loss: 1.1758 - accuracy: 0.5799\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 72s 67ms/step - loss: 1.0457 - accuracy: 0.6269\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 71s 66ms/step - loss: 0.9597 - accuracy: 0.6613\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 0.8869 - accuracy: 0.6873\n",
            "Score for fold 3: loss of 1.0247066020965576; accuracy of 63.91666531562805%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 70s 64ms/step - loss: 1.4985 - accuracy: 0.4519\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 69s 64ms/step - loss: 1.0717 - accuracy: 0.6199\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 72s 67ms/step - loss: 0.9145 - accuracy: 0.6793\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 70s 64ms/step - loss: 0.8038 - accuracy: 0.7195\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 71s 66ms/step - loss: 0.7174 - accuracy: 0.7502\n",
            "Score for fold 4: loss of 0.8619261980056763; accuracy of 70.2833354473114%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 71s 65ms/step - loss: 1.4812 - accuracy: 0.4599\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 72s 67ms/step - loss: 1.0876 - accuracy: 0.6130\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 69s 64ms/step - loss: 0.9473 - accuracy: 0.6666\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 71s 66ms/step - loss: 0.8488 - accuracy: 0.7006\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 0.7735 - accuracy: 0.7293\n",
            "Score for fold 5: loss of 0.9074341058731079; accuracy of 68.36666464805603%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 70s 64ms/step - loss: 1.4972 - accuracy: 0.4586\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 71s 66ms/step - loss: 1.0974 - accuracy: 0.6117\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 0.9569 - accuracy: 0.6640\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 69s 64ms/step - loss: 0.8661 - accuracy: 0.6962\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 0.7911 - accuracy: 0.7228\n",
            "Score for fold 6: loss of 0.9251077771186829; accuracy of 67.79999732971191%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 72s 65ms/step - loss: 1.5381 - accuracy: 0.4368\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 69s 64ms/step - loss: 1.1027 - accuracy: 0.6062\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 71s 65ms/step - loss: 0.9530 - accuracy: 0.6649\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 0.8532 - accuracy: 0.7018\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 72s 67ms/step - loss: 0.7735 - accuracy: 0.7285\n",
            "Score for fold 7: loss of 0.9596310257911682; accuracy of 67.43333339691162%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 70s 64ms/step - loss: 1.6264 - accuracy: 0.4121\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 1.2124 - accuracy: 0.5688\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 71s 66ms/step - loss: 1.0755 - accuracy: 0.6190\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 0.9783 - accuracy: 0.6561\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 71s 66ms/step - loss: 0.9078 - accuracy: 0.6805\n",
            "Score for fold 8: loss of 1.0187476873397827; accuracy of 64.63333368301392%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 70s 65ms/step - loss: 1.5624 - accuracy: 0.4283\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 76s 71ms/step - loss: 1.1874 - accuracy: 0.5772\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 76s 71ms/step - loss: 1.0311 - accuracy: 0.6367\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 77s 72ms/step - loss: 0.9309 - accuracy: 0.6722\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 77s 72ms/step - loss: 0.8580 - accuracy: 0.6998\n",
            "Score for fold 9: loss of 0.9729888439178467; accuracy of 66.79999828338623%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/5\n",
            "1080/1080 [==============================] - 78s 72ms/step - loss: 1.4645 - accuracy: 0.4662\n",
            "Epoch 2/5\n",
            "1080/1080 [==============================] - 77s 72ms/step - loss: 1.0842 - accuracy: 0.6159\n",
            "Epoch 3/5\n",
            "1080/1080 [==============================] - 78s 72ms/step - loss: 0.9495 - accuracy: 0.6650\n",
            "Epoch 4/5\n",
            "1080/1080 [==============================] - 77s 71ms/step - loss: 0.8562 - accuracy: 0.6971\n",
            "Epoch 5/5\n",
            "1080/1080 [==============================] - 77s 72ms/step - loss: 0.7827 - accuracy: 0.7265\n",
            "Score for fold 10: loss of 0.9122653603553772; accuracy of 68.69999766349792%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.8648485541343689 - Accuracy: 70.45000195503235%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.9767177700996399 - Accuracy: 64.98333215713501%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.0247066020965576 - Accuracy: 63.91666531562805%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.8619261980056763 - Accuracy: 70.2833354473114%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.9074341058731079 - Accuracy: 68.36666464805603%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.9251077771186829 - Accuracy: 67.79999732971191%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.9596310257911682 - Accuracy: 67.43333339691162%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 1.0187476873397827 - Accuracy: 64.63333368301392%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.9729888439178467 - Accuracy: 66.79999828338623%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.9122653603553772 - Accuracy: 68.69999766349792%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 67.33666598796844 (+- 2.1529030460803917)\n",
            "> Loss: 0.9424373924732208\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}