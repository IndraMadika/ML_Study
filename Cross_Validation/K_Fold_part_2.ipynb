{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2yEagOJSxXTXBSXP9UZBA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndraMadika/ML_Study/blob/main/Cross_Validation/K_Fold_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rW5dVJDejr1D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "EXnOa0ogkf3h",
        "outputId": "e5ea2a8b-4924-493f-c211-f0887ab2f289"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aab82c77-210e-469d-b895-bbec97e33b62\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aab82c77-210e-469d-b895-bbec97e33b62\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cardio_train.csv to cardio_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rootPath='/content/'\n",
        "dfDS = pd.read_csv(rootPath+\"cardio_train.csv\", delimiter=';')"
      ],
      "metadata": {
        "id": "1poYOCsvlE-Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=====Split Dataset=======\n",
        "X = dfDS.iloc[:, 1:len(dfDS.columns)-1].values\n",
        "Y = dfDS[\"cardio\"].values\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20)"
      ],
      "metadata": {
        "id": "v0bRTeYnlMT8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=====Feature Scaling======\n",
        "columnsToScale = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "xTrain = scaler.fit_transform(xTrain)\n",
        "xTest = scaler.transform(xTest)"
      ],
      "metadata": {
        "id": "o-jEkjxul6Nw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verbose, epochs, batch_size = 1, 100, 512\n",
        "activationFunction='relu'\n",
        "\n",
        "def getModel():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, input_dim = xTrain.shape[1], activation=activationFunction))\n",
        "    model.add(Dense(75, activation=activationFunction))\n",
        "    model.add(Dense(50, activation=activationFunction))\n",
        "    model.add(Dense(25, activation=activationFunction))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = getModel()"
      ],
      "metadata": {
        "id": "Q9S_tVmJl7BJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def showResults(test, pred):\n",
        "    target_names = ['positive', 'negative']\n",
        "    print(classification_report(test, pred, target_names=target_names))\n",
        "    accuracy = accuracy_score(test, pred)\n",
        "    precision=precision_score(test, pred, average='weighted')\n",
        "    f1Score=f1_score(test, pred, average='weighted')\n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1Score))\n",
        "    cm=confusion_matrix(test, pred)\n",
        "    print(cm)"
      ],
      "metadata": {
        "id": "sWuH9FWlmA2A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#======== Cross Validation ===========\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "skf.get_n_splits(xTrain, yTrain)\n",
        "foldNum=0\n",
        "for train_index, val_index in skf.split(xTrain, yTrain):\n",
        "    foldNum+=1\n",
        "    print(\"Results for fold\",foldNum)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "\n",
        "    # one hot encode\n",
        "    Y_train = to_categorical(Y_train)\n",
        "    Y_val = to_categorical(Y_val)\n",
        "\n",
        "    history = model.fit(X_train, Y_train,\n",
        "                        validation_data = (X_val, Y_val),\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size)\n",
        "    yPredict = model.predict(X_val)\n",
        "\n",
        "    #Converting one hot encoded test label to label\n",
        "    pred = np.argmax(yPredict, axis=1)\n",
        "    val = np.argmax(Y_val, axis=1)\n",
        "\n",
        "    showResults(val, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7SLi8UJmDOR",
        "outputId": "9601ad6b-1cde-4ac4-fc43-2d4783756e4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for fold 1\n",
            "Epoch 1/100\n",
            "88/88 [==============================] - 3s 14ms/step - loss: 21.3043 - accuracy: 0.4989 - val_loss: 16.2166 - val_accuracy: 0.5029\n",
            "Epoch 2/100\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 11.0249 - accuracy: 0.5099 - val_loss: 2.3248 - val_accuracy: 0.5027\n",
            "Epoch 3/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 13.9691 - accuracy: 0.5039 - val_loss: 13.7813 - val_accuracy: 0.4985\n",
            "Epoch 4/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 9.2044 - accuracy: 0.5101 - val_loss: 4.1411 - val_accuracy: 0.5054\n",
            "Epoch 5/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 6.6629 - accuracy: 0.5077 - val_loss: 8.7434 - val_accuracy: 0.5029\n",
            "Epoch 6/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 4.7995 - accuracy: 0.5136 - val_loss: 3.1457 - val_accuracy: 0.6063\n",
            "Epoch 7/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 6.2915 - accuracy: 0.5224 - val_loss: 1.6425 - val_accuracy: 0.5029\n",
            "Epoch 8/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 4.4786 - accuracy: 0.5215 - val_loss: 5.5804 - val_accuracy: 0.5029\n",
            "Epoch 9/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 5.0837 - accuracy: 0.5230 - val_loss: 1.8588 - val_accuracy: 0.5746\n",
            "Epoch 10/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 3.4337 - accuracy: 0.5179 - val_loss: 1.7602 - val_accuracy: 0.6049\n",
            "Epoch 11/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 3.5134 - accuracy: 0.5160 - val_loss: 4.9226 - val_accuracy: 0.5029\n",
            "Epoch 12/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 4.2899 - accuracy: 0.5133 - val_loss: 5.5305 - val_accuracy: 0.4974\n",
            "Epoch 13/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 4.0851 - accuracy: 0.5070 - val_loss: 1.5878 - val_accuracy: 0.6361\n",
            "Epoch 14/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 2.2779 - accuracy: 0.5138 - val_loss: 0.7826 - val_accuracy: 0.5873\n",
            "Epoch 15/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.6745 - accuracy: 0.5404 - val_loss: 2.4440 - val_accuracy: 0.5071\n",
            "Epoch 16/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 3.7062 - accuracy: 0.5272 - val_loss: 2.9239 - val_accuracy: 0.5029\n",
            "Epoch 17/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 2.6637 - accuracy: 0.5228 - val_loss: 0.7761 - val_accuracy: 0.5576\n",
            "Epoch 18/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.9649 - accuracy: 0.5219 - val_loss: 2.0225 - val_accuracy: 0.5029\n",
            "Epoch 19/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 1.8371 - accuracy: 0.5284 - val_loss: 0.7850 - val_accuracy: 0.5944\n",
            "Epoch 20/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.3106 - accuracy: 0.5469 - val_loss: 1.0697 - val_accuracy: 0.5218\n",
            "Epoch 21/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.4558 - accuracy: 0.5590 - val_loss: 0.9303 - val_accuracy: 0.5052\n",
            "Epoch 22/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.1970 - accuracy: 0.5492 - val_loss: 0.7499 - val_accuracy: 0.5296\n",
            "Epoch 23/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.9422 - accuracy: 0.5714 - val_loss: 1.3289 - val_accuracy: 0.5033\n",
            "Epoch 24/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7960 - accuracy: 0.5762 - val_loss: 1.0047 - val_accuracy: 0.5092\n",
            "Epoch 25/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.8256 - accuracy: 0.5742 - val_loss: 0.6325 - val_accuracy: 0.6817\n",
            "Epoch 26/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 1.4333 - accuracy: 0.5406 - val_loss: 0.6155 - val_accuracy: 0.6841\n",
            "Epoch 27/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 1.3747 - accuracy: 0.5426 - val_loss: 3.5724 - val_accuracy: 0.4973\n",
            "Epoch 28/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.3791 - accuracy: 0.5688 - val_loss: 1.3625 - val_accuracy: 0.5089\n",
            "Epoch 29/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7893 - accuracy: 0.5799 - val_loss: 0.6394 - val_accuracy: 0.6448\n",
            "Epoch 30/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.8169 - accuracy: 0.5849 - val_loss: 0.9948 - val_accuracy: 0.5070\n",
            "Epoch 31/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7934 - accuracy: 0.5955 - val_loss: 1.4076 - val_accuracy: 0.5034\n",
            "Epoch 32/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.6879 - accuracy: 0.5404 - val_loss: 1.4832 - val_accuracy: 0.5031\n",
            "Epoch 33/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.8178 - accuracy: 0.6043 - val_loss: 1.2827 - val_accuracy: 0.5033\n",
            "Epoch 34/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7683 - accuracy: 0.5907 - val_loss: 0.9596 - val_accuracy: 0.5094\n",
            "Epoch 35/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7095 - accuracy: 0.6273 - val_loss: 0.7794 - val_accuracy: 0.5562\n",
            "Epoch 36/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.9409 - accuracy: 0.5801 - val_loss: 5.3879 - val_accuracy: 0.4971\n",
            "Epoch 37/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 4.0534 - accuracy: 0.5093 - val_loss: 1.8006 - val_accuracy: 0.4971\n",
            "Epoch 38/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 2.3294 - accuracy: 0.5078 - val_loss: 0.7837 - val_accuracy: 0.5029\n",
            "Epoch 39/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 1.0834 - accuracy: 0.5131 - val_loss: 0.7936 - val_accuracy: 0.5029\n",
            "Epoch 40/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.9255 - accuracy: 0.5311 - val_loss: 2.8048 - val_accuracy: 0.4971\n",
            "Epoch 41/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.4894 - accuracy: 0.5041 - val_loss: 1.3910 - val_accuracy: 0.5054\n",
            "Epoch 42/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 1.1504 - accuracy: 0.5077 - val_loss: 1.4128 - val_accuracy: 0.5054\n",
            "Epoch 43/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 1.0719 - accuracy: 0.5086 - val_loss: 0.6868 - val_accuracy: 0.5429\n",
            "Epoch 44/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.5753 - val_loss: 0.8541 - val_accuracy: 0.5029\n",
            "Epoch 45/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5947 - val_loss: 0.7523 - val_accuracy: 0.5038\n",
            "Epoch 46/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7112 - accuracy: 0.5847 - val_loss: 0.6597 - val_accuracy: 0.6787\n",
            "Epoch 47/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5927 - val_loss: 0.7647 - val_accuracy: 0.5058\n",
            "Epoch 48/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7053 - accuracy: 0.5829 - val_loss: 0.7202 - val_accuracy: 0.6925\n",
            "Epoch 49/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.6248 - val_loss: 0.9060 - val_accuracy: 0.5029\n",
            "Epoch 50/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.5996 - val_loss: 0.7093 - val_accuracy: 0.5782\n",
            "Epoch 51/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7254 - accuracy: 0.5744 - val_loss: 0.8722 - val_accuracy: 0.5034\n",
            "Epoch 52/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7190 - accuracy: 0.5825 - val_loss: 0.6754 - val_accuracy: 0.5429\n",
            "Epoch 53/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5990 - val_loss: 0.7346 - val_accuracy: 0.5118\n",
            "Epoch 54/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.5709 - val_loss: 0.6747 - val_accuracy: 0.5554\n",
            "Epoch 55/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7142 - accuracy: 0.5888 - val_loss: 0.6473 - val_accuracy: 0.6850\n",
            "Epoch 56/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7571 - accuracy: 0.5605 - val_loss: 0.8236 - val_accuracy: 0.5115\n",
            "Epoch 57/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.6182 - val_loss: 0.6547 - val_accuracy: 0.6879\n",
            "Epoch 58/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.5905 - val_loss: 0.6984 - val_accuracy: 0.6035\n",
            "Epoch 59/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.6284 - val_loss: 0.6303 - val_accuracy: 0.6839\n",
            "Epoch 60/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7027 - accuracy: 0.6123 - val_loss: 1.1557 - val_accuracy: 0.5031\n",
            "Epoch 61/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7338 - accuracy: 0.6110 - val_loss: 0.6722 - val_accuracy: 0.5978\n",
            "Epoch 62/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.6084 - val_loss: 0.6886 - val_accuracy: 0.5569\n",
            "Epoch 63/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.5959 - val_loss: 0.6259 - val_accuracy: 0.6976\n",
            "Epoch 64/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.5969 - val_loss: 1.1427 - val_accuracy: 0.5035\n",
            "Epoch 65/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.6014 - val_loss: 0.6295 - val_accuracy: 0.6990\n",
            "Epoch 66/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.6097 - val_loss: 0.7969 - val_accuracy: 0.5141\n",
            "Epoch 67/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7047 - accuracy: 0.6160 - val_loss: 0.8590 - val_accuracy: 0.5137\n",
            "Epoch 68/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.6246 - val_loss: 0.6132 - val_accuracy: 0.6969\n",
            "Epoch 69/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.6182 - val_loss: 0.6993 - val_accuracy: 0.5855\n",
            "Epoch 70/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6528 - val_loss: 0.7448 - val_accuracy: 0.5487\n",
            "Epoch 71/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7191 - accuracy: 0.6065 - val_loss: 0.8181 - val_accuracy: 0.5604\n",
            "Epoch 72/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.8378 - accuracy: 0.5853 - val_loss: 0.7291 - val_accuracy: 0.5724\n",
            "Epoch 73/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6860 - accuracy: 0.6359 - val_loss: 0.6203 - val_accuracy: 0.6962\n",
            "Epoch 74/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.8760 - accuracy: 0.5962 - val_loss: 1.1092 - val_accuracy: 0.5031\n",
            "Epoch 75/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.9252 - accuracy: 0.5226 - val_loss: 0.6500 - val_accuracy: 0.7008\n",
            "Epoch 76/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6527 - val_loss: 0.6266 - val_accuracy: 0.6979\n",
            "Epoch 77/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.6528 - val_loss: 0.6367 - val_accuracy: 0.6764\n",
            "Epoch 78/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6602 - val_loss: 0.6654 - val_accuracy: 0.5877\n",
            "Epoch 79/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6762 - val_loss: 0.6318 - val_accuracy: 0.6669\n",
            "Epoch 80/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.6451 - val_loss: 0.6954 - val_accuracy: 0.5752\n",
            "Epoch 81/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6489 - val_loss: 0.8241 - val_accuracy: 0.5179\n",
            "Epoch 82/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6438 - val_loss: 0.6158 - val_accuracy: 0.6912\n",
            "Epoch 83/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6293 - val_loss: 0.6120 - val_accuracy: 0.6834\n",
            "Epoch 84/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6844 - val_loss: 0.6143 - val_accuracy: 0.7021\n",
            "Epoch 85/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6648 - val_loss: 0.6058 - val_accuracy: 0.7025\n",
            "Epoch 86/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.6326 - val_loss: 0.6944 - val_accuracy: 0.5804\n",
            "Epoch 87/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6444 - val_loss: 0.6137 - val_accuracy: 0.6861\n",
            "Epoch 88/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.6346 - val_loss: 0.6127 - val_accuracy: 0.6941\n",
            "Epoch 89/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.6640 - val_loss: 0.6107 - val_accuracy: 0.6979\n",
            "Epoch 90/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6477 - val_loss: 0.6839 - val_accuracy: 0.5893\n",
            "Epoch 91/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.6643 - val_loss: 0.6868 - val_accuracy: 0.5767\n",
            "Epoch 92/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6578 - val_loss: 0.6249 - val_accuracy: 0.6739\n",
            "Epoch 93/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6556 - val_loss: 0.6286 - val_accuracy: 0.6589\n",
            "Epoch 94/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.6607 - val_loss: 0.6385 - val_accuracy: 0.6972\n",
            "Epoch 95/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.6484 - val_loss: 1.0035 - val_accuracy: 0.5301\n",
            "Epoch 96/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 1.7422 - accuracy: 0.5480 - val_loss: 0.6567 - val_accuracy: 0.6670\n",
            "Epoch 97/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.6202 - val_loss: 0.6444 - val_accuracy: 0.7029\n",
            "Epoch 98/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6584 - val_loss: 0.6565 - val_accuracy: 0.6187\n",
            "Epoch 99/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6389 - val_loss: 0.6500 - val_accuracy: 0.6160\n",
            "Epoch 100/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6465 - val_loss: 0.6596 - val_accuracy: 0.6071\n",
            "350/350 [==============================] - 0s 812us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.56      0.95      0.71      5567\n",
            "    negative       0.85      0.27      0.41      5633\n",
            "\n",
            "    accuracy                           0.61     11200\n",
            "   macro avg       0.70      0.61      0.56     11200\n",
            "weighted avg       0.71      0.61      0.56     11200\n",
            "\n",
            "Accuracy  : 0.6071428571428571\n",
            "Precision : 0.7056483533288466\n",
            "f1Score : 0.5553323228652339\n",
            "[[5297  270]\n",
            " [4130 1503]]\n",
            "Results for fold 2\n",
            "Epoch 1/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6367 - val_loss: 0.6921 - val_accuracy: 0.5267\n",
            "Epoch 2/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6467 - val_loss: 0.6521 - val_accuracy: 0.6053\n",
            "Epoch 3/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6236 - val_loss: 0.6268 - val_accuracy: 0.6658\n",
            "Epoch 4/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6388 - val_loss: 0.6529 - val_accuracy: 0.5933\n",
            "Epoch 5/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6279 - val_loss: 0.6247 - val_accuracy: 0.6816\n",
            "Epoch 6/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6427 - val_loss: 0.6138 - val_accuracy: 0.7175\n",
            "Epoch 7/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.6212 - val_loss: 0.6778 - val_accuracy: 0.5800\n",
            "Epoch 8/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.6558 - val_loss: 0.6409 - val_accuracy: 0.7100\n",
            "Epoch 9/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.6554 - val_loss: 0.6619 - val_accuracy: 0.5731\n",
            "Epoch 10/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6485 - val_loss: 0.6328 - val_accuracy: 0.6760\n",
            "Epoch 11/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6710 - val_loss: 0.6331 - val_accuracy: 0.6644\n",
            "Epoch 12/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.6348 - val_loss: 0.6305 - val_accuracy: 0.7220\n",
            "Epoch 13/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6690 - val_loss: 0.6239 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6420 - val_loss: 0.6297 - val_accuracy: 0.6447\n",
            "Epoch 15/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6514 - val_loss: 0.6748 - val_accuracy: 0.5748\n",
            "Epoch 16/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6450 - val_loss: 0.7238 - val_accuracy: 0.5354\n",
            "Epoch 17/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.6512 - val_loss: 0.6506 - val_accuracy: 0.6002\n",
            "Epoch 18/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6266 - val_loss: 0.6107 - val_accuracy: 0.7026\n",
            "Epoch 19/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6804 - val_loss: 0.6404 - val_accuracy: 0.6365\n",
            "Epoch 20/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6887 - val_loss: 0.6146 - val_accuracy: 0.6826\n",
            "Epoch 21/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6190 - accuracy: 0.6704 - val_loss: 0.6186 - val_accuracy: 0.6691\n",
            "Epoch 22/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6420 - accuracy: 0.6441 - val_loss: 0.6039 - val_accuracy: 0.7185\n",
            "Epoch 23/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6244 - accuracy: 0.6705 - val_loss: 0.6063 - val_accuracy: 0.7072\n",
            "Epoch 24/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.6707 - val_loss: 0.6459 - val_accuracy: 0.6305\n",
            "Epoch 25/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.6635 - val_loss: 0.6241 - val_accuracy: 0.6717\n",
            "Epoch 26/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6734 - val_loss: 0.6171 - val_accuracy: 0.6687\n",
            "Epoch 27/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6678 - val_loss: 0.6088 - val_accuracy: 0.6848\n",
            "Epoch 28/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.6707 - val_loss: 0.6220 - val_accuracy: 0.6696\n",
            "Epoch 29/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6460 - val_loss: 0.6812 - val_accuracy: 0.5869\n",
            "Epoch 30/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.6107 - val_loss: 0.6388 - val_accuracy: 0.6574\n",
            "Epoch 31/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6482 - val_loss: 0.6953 - val_accuracy: 0.5318\n",
            "Epoch 32/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6020 - val_loss: 0.7834 - val_accuracy: 0.5138\n",
            "Epoch 33/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6287 - val_loss: 0.6378 - val_accuracy: 0.6454\n",
            "Epoch 34/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6744 - val_loss: 0.6406 - val_accuracy: 0.6246\n",
            "Epoch 35/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6604 - val_loss: 0.6404 - val_accuracy: 0.6216\n",
            "Epoch 36/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6552 - val_loss: 0.6240 - val_accuracy: 0.7072\n",
            "Epoch 37/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6504 - val_loss: 0.6125 - val_accuracy: 0.6876\n",
            "Epoch 38/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6861 - val_loss: 0.6477 - val_accuracy: 0.6053\n",
            "Epoch 39/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6725 - val_loss: 0.6051 - val_accuracy: 0.7140\n",
            "Epoch 40/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6810 - val_loss: 0.6247 - val_accuracy: 0.6603\n",
            "Epoch 41/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6581 - val_loss: 0.6071 - val_accuracy: 0.6996\n",
            "Epoch 42/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.6675 - val_loss: 0.6051 - val_accuracy: 0.6923\n",
            "Epoch 43/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6794 - val_loss: 0.7785 - val_accuracy: 0.5219\n",
            "Epoch 44/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6165 - accuracy: 0.6752 - val_loss: 0.6450 - val_accuracy: 0.6196\n",
            "Epoch 45/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6859 - val_loss: 0.5934 - val_accuracy: 0.7162\n",
            "Epoch 46/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.6790 - val_loss: 0.6759 - val_accuracy: 0.5833\n",
            "Epoch 47/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 1.3194 - accuracy: 0.5528 - val_loss: 0.7387 - val_accuracy: 0.5016\n",
            "Epoch 48/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.6261 - val_loss: 0.7081 - val_accuracy: 0.5171\n",
            "Epoch 49/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6397 - val_loss: 0.6531 - val_accuracy: 0.6350\n",
            "Epoch 50/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6326 - val_loss: 0.6295 - val_accuracy: 0.7102\n",
            "Epoch 51/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6633 - val_loss: 0.6366 - val_accuracy: 0.6420\n",
            "Epoch 52/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6774 - val_loss: 0.6272 - val_accuracy: 0.6621\n",
            "Epoch 53/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6736 - val_loss: 0.6232 - val_accuracy: 0.6752\n",
            "Epoch 54/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6772 - val_loss: 0.6029 - val_accuracy: 0.7179\n",
            "Epoch 55/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6720 - val_loss: 0.6033 - val_accuracy: 0.7154\n",
            "Epoch 56/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6299 - accuracy: 0.6511 - val_loss: 0.6010 - val_accuracy: 0.7144\n",
            "Epoch 57/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6067 - accuracy: 0.6881 - val_loss: 0.6072 - val_accuracy: 0.6927\n",
            "Epoch 58/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6100 - accuracy: 0.6812 - val_loss: 0.6029 - val_accuracy: 0.6960\n",
            "Epoch 59/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6686 - val_loss: 0.6527 - val_accuracy: 0.6112\n",
            "Epoch 60/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.6844 - val_loss: 0.5912 - val_accuracy: 0.7195\n",
            "Epoch 61/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6730 - val_loss: 0.6470 - val_accuracy: 0.6174\n",
            "Epoch 62/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6938 - val_loss: 0.6041 - val_accuracy: 0.6953\n",
            "Epoch 63/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6659 - val_loss: 0.6275 - val_accuracy: 0.6590\n",
            "Epoch 64/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6718 - val_loss: 0.6159 - val_accuracy: 0.6929\n",
            "Epoch 65/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6891 - val_loss: 0.6388 - val_accuracy: 0.6208\n",
            "Epoch 66/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6728 - val_loss: 0.6029 - val_accuracy: 0.7209\n",
            "Epoch 67/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6859 - val_loss: 0.6245 - val_accuracy: 0.6602\n",
            "Epoch 68/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.6908 - val_loss: 0.5938 - val_accuracy: 0.7170\n",
            "Epoch 69/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.6879 - val_loss: 0.6379 - val_accuracy: 0.6421\n",
            "Epoch 70/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6771 - val_loss: 0.5971 - val_accuracy: 0.7102\n",
            "Epoch 71/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6875 - val_loss: 0.6218 - val_accuracy: 0.6587\n",
            "Epoch 72/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6935 - val_loss: 0.6062 - val_accuracy: 0.6888\n",
            "Epoch 73/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.6774 - val_loss: 0.6170 - val_accuracy: 0.6729\n",
            "Epoch 74/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.6744 - val_loss: 0.6815 - val_accuracy: 0.5945\n",
            "Epoch 75/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6603 - val_loss: 0.5927 - val_accuracy: 0.7206\n",
            "Epoch 76/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.6819 - val_loss: 0.6821 - val_accuracy: 0.5838\n",
            "Epoch 77/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6754 - val_loss: 0.5973 - val_accuracy: 0.7154\n",
            "Epoch 78/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6987 - val_loss: 0.5937 - val_accuracy: 0.7151\n",
            "Epoch 79/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6979 - val_loss: 0.6284 - val_accuracy: 0.6628\n",
            "Epoch 80/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6887 - val_loss: 0.5942 - val_accuracy: 0.7189\n",
            "Epoch 81/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6855 - val_loss: 0.5882 - val_accuracy: 0.7184\n",
            "Epoch 82/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7021 - val_loss: 0.5922 - val_accuracy: 0.7163\n",
            "Epoch 83/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.6991 - val_loss: 0.6067 - val_accuracy: 0.6790\n",
            "Epoch 84/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6719 - val_loss: 0.5853 - val_accuracy: 0.7212\n",
            "Epoch 85/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6949 - val_loss: 0.6152 - val_accuracy: 0.6702\n",
            "Epoch 86/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.7023 - val_loss: 0.5856 - val_accuracy: 0.7196\n",
            "Epoch 87/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.6915 - val_loss: 0.6036 - val_accuracy: 0.6899\n",
            "Epoch 88/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.6987 - val_loss: 0.5887 - val_accuracy: 0.7107\n",
            "Epoch 89/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.7033 - val_loss: 0.5817 - val_accuracy: 0.7210\n",
            "Epoch 90/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.6985 - val_loss: 0.5883 - val_accuracy: 0.7104\n",
            "Epoch 91/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.7044 - val_loss: 0.5795 - val_accuracy: 0.7201\n",
            "Epoch 92/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6009 - accuracy: 0.6891 - val_loss: 0.5956 - val_accuracy: 0.7004\n",
            "Epoch 93/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5929 - accuracy: 0.6956 - val_loss: 0.6384 - val_accuracy: 0.6571\n",
            "Epoch 94/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.6983 - val_loss: 0.5779 - val_accuracy: 0.7212\n",
            "Epoch 95/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.7006 - val_loss: 0.6048 - val_accuracy: 0.6880\n",
            "Epoch 96/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7055 - val_loss: 0.5741 - val_accuracy: 0.7204\n",
            "Epoch 97/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6961 - val_loss: 0.5735 - val_accuracy: 0.7221\n",
            "Epoch 98/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7030 - val_loss: 0.6172 - val_accuracy: 0.6762\n",
            "Epoch 99/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6996 - val_loss: 0.5747 - val_accuracy: 0.7219\n",
            "Epoch 100/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6895 - val_loss: 0.5999 - val_accuracy: 0.6837\n",
            "350/350 [==============================] - 0s 839us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.76      0.53      0.63      5614\n",
            "    negative       0.64      0.84      0.72      5586\n",
            "\n",
            "    accuracy                           0.68     11200\n",
            "   macro avg       0.70      0.68      0.68     11200\n",
            "weighted avg       0.70      0.68      0.68     11200\n",
            "\n",
            "Accuracy  : 0.68375\n",
            "Precision : 0.7026840904677886\n",
            "f1Score : 0.6764028067742026\n",
            "[[2992 2622]\n",
            " [ 920 4666]]\n",
            "Results for fold 3\n",
            "Epoch 1/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.7008 - val_loss: 0.6564 - val_accuracy: 0.6371\n",
            "Epoch 2/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6962 - val_loss: 0.5764 - val_accuracy: 0.7108\n",
            "Epoch 3/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.6958 - val_loss: 0.5816 - val_accuracy: 0.7067\n",
            "Epoch 4/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7061 - val_loss: 0.5799 - val_accuracy: 0.7100\n",
            "Epoch 5/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7067 - val_loss: 0.5981 - val_accuracy: 0.6817\n",
            "Epoch 6/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7092 - val_loss: 0.5764 - val_accuracy: 0.7115\n",
            "Epoch 7/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7043 - val_loss: 0.5749 - val_accuracy: 0.7107\n",
            "Epoch 8/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7058 - val_loss: 0.5894 - val_accuracy: 0.6952\n",
            "Epoch 9/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.7062 - val_loss: 0.5729 - val_accuracy: 0.7122\n",
            "Epoch 10/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.7036 - val_loss: 0.5752 - val_accuracy: 0.7108\n",
            "Epoch 11/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7060 - val_loss: 0.5741 - val_accuracy: 0.7182\n",
            "Epoch 12/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.6957 - val_loss: 0.5893 - val_accuracy: 0.7045\n",
            "Epoch 13/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7024 - val_loss: 0.5763 - val_accuracy: 0.7120\n",
            "Epoch 14/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7044 - val_loss: 0.5763 - val_accuracy: 0.7138\n",
            "Epoch 15/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.7055 - val_loss: 0.5730 - val_accuracy: 0.7168\n",
            "Epoch 16/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7044 - val_loss: 0.5775 - val_accuracy: 0.7066\n",
            "Epoch 17/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7031 - val_loss: 0.5806 - val_accuracy: 0.7057\n",
            "Epoch 18/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7073 - val_loss: 0.5731 - val_accuracy: 0.7121\n",
            "Epoch 19/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7074 - val_loss: 0.5879 - val_accuracy: 0.7081\n",
            "Epoch 20/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7001 - val_loss: 0.5757 - val_accuracy: 0.7145\n",
            "Epoch 21/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7100 - val_loss: 0.5775 - val_accuracy: 0.7119\n",
            "Epoch 22/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7108 - val_loss: 0.5776 - val_accuracy: 0.7112\n",
            "Epoch 23/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7094 - val_loss: 0.5988 - val_accuracy: 0.6958\n",
            "Epoch 24/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5881 - accuracy: 0.6997 - val_loss: 0.5929 - val_accuracy: 0.6963\n",
            "Epoch 25/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5804 - accuracy: 0.7090 - val_loss: 0.5933 - val_accuracy: 0.6977\n",
            "Epoch 26/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5802 - accuracy: 0.7074 - val_loss: 0.5951 - val_accuracy: 0.6975\n",
            "Epoch 27/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5824 - accuracy: 0.7048 - val_loss: 0.6059 - val_accuracy: 0.6682\n",
            "Epoch 28/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7092 - val_loss: 0.5844 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7097 - val_loss: 0.5778 - val_accuracy: 0.7139\n",
            "Epoch 30/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7050 - val_loss: 0.6102 - val_accuracy: 0.6637\n",
            "Epoch 31/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7019 - val_loss: 0.5769 - val_accuracy: 0.7164\n",
            "Epoch 32/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7066 - val_loss: 0.6147 - val_accuracy: 0.6569\n",
            "Epoch 33/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.7026 - val_loss: 0.5757 - val_accuracy: 0.7185\n",
            "Epoch 34/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.7036 - val_loss: 0.6150 - val_accuracy: 0.6544\n",
            "Epoch 35/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7107 - val_loss: 0.5786 - val_accuracy: 0.7109\n",
            "Epoch 36/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6952 - val_loss: 0.5796 - val_accuracy: 0.7054\n",
            "Epoch 37/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7007 - val_loss: 0.5944 - val_accuracy: 0.6835\n",
            "Epoch 38/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.7021 - val_loss: 0.5875 - val_accuracy: 0.7022\n",
            "Epoch 39/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.7099 - val_loss: 0.5715 - val_accuracy: 0.7185\n",
            "Epoch 40/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7109 - val_loss: 0.5725 - val_accuracy: 0.7139\n",
            "Epoch 41/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7091 - val_loss: 0.6514 - val_accuracy: 0.6248\n",
            "Epoch 42/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7088 - val_loss: 0.5787 - val_accuracy: 0.7087\n",
            "Epoch 43/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7085 - val_loss: 0.5765 - val_accuracy: 0.7111\n",
            "Epoch 44/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7087 - val_loss: 0.5732 - val_accuracy: 0.7120\n",
            "Epoch 45/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.7041 - val_loss: 0.6075 - val_accuracy: 0.7097\n",
            "Epoch 46/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.6996 - val_loss: 0.5977 - val_accuracy: 0.6996\n",
            "Epoch 47/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.6984 - val_loss: 0.5841 - val_accuracy: 0.7049\n",
            "Epoch 48/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7092 - val_loss: 0.5811 - val_accuracy: 0.7075\n",
            "Epoch 49/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.6960 - val_loss: 0.5947 - val_accuracy: 0.6925\n",
            "Epoch 50/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7035 - val_loss: 0.5788 - val_accuracy: 0.7111\n",
            "Epoch 51/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7053 - val_loss: 0.5985 - val_accuracy: 0.6814\n",
            "Epoch 52/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.6962 - val_loss: 0.5773 - val_accuracy: 0.7138\n",
            "Epoch 53/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7133 - val_loss: 0.5893 - val_accuracy: 0.6947\n",
            "Epoch 54/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7151 - val_loss: 0.5715 - val_accuracy: 0.7160\n",
            "Epoch 55/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.7110 - val_loss: 0.5719 - val_accuracy: 0.7138\n",
            "Epoch 56/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7061 - val_loss: 0.6140 - val_accuracy: 0.6791\n",
            "Epoch 57/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6982 - val_loss: 0.5741 - val_accuracy: 0.7113\n",
            "Epoch 58/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5790 - accuracy: 0.7093 - val_loss: 0.5772 - val_accuracy: 0.7073\n",
            "Epoch 59/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5762 - accuracy: 0.7103 - val_loss: 0.5746 - val_accuracy: 0.7106\n",
            "Epoch 60/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.7057 - val_loss: 0.6008 - val_accuracy: 0.6784\n",
            "Epoch 61/100\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5833 - accuracy: 0.7005 - val_loss: 0.5915 - val_accuracy: 0.6912\n",
            "Epoch 62/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.7023 - val_loss: 0.5741 - val_accuracy: 0.7126\n",
            "Epoch 63/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7081 - val_loss: 0.5717 - val_accuracy: 0.7131\n",
            "Epoch 64/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7092 - val_loss: 0.5723 - val_accuracy: 0.7210\n",
            "Epoch 65/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7085 - val_loss: 0.5715 - val_accuracy: 0.7145\n",
            "Epoch 66/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7050 - val_loss: 0.5702 - val_accuracy: 0.7165\n",
            "Epoch 67/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.7048 - val_loss: 0.5847 - val_accuracy: 0.7104\n",
            "Epoch 68/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7061 - val_loss: 0.6272 - val_accuracy: 0.6464\n",
            "Epoch 69/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7079 - val_loss: 0.5717 - val_accuracy: 0.7144\n",
            "Epoch 70/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7092 - val_loss: 0.5858 - val_accuracy: 0.6988\n",
            "Epoch 71/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5749 - accuracy: 0.7100 - val_loss: 0.5672 - val_accuracy: 0.7188\n",
            "Epoch 72/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.7048 - val_loss: 0.5848 - val_accuracy: 0.6952\n",
            "Epoch 73/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.7098 - val_loss: 0.5814 - val_accuracy: 0.7036\n",
            "Epoch 74/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.7146 - val_loss: 0.5734 - val_accuracy: 0.7116\n",
            "Epoch 75/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.7088 - val_loss: 0.5775 - val_accuracy: 0.7033\n",
            "Epoch 76/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7055 - val_loss: 0.5818 - val_accuracy: 0.6974\n",
            "Epoch 77/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7101 - val_loss: 0.5741 - val_accuracy: 0.7173\n",
            "Epoch 78/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7129 - val_loss: 0.5874 - val_accuracy: 0.6938\n",
            "Epoch 79/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7119 - val_loss: 0.5693 - val_accuracy: 0.7146\n",
            "Epoch 80/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7148 - val_loss: 0.5699 - val_accuracy: 0.7133\n",
            "Epoch 81/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7075 - val_loss: 0.5685 - val_accuracy: 0.7148\n",
            "Epoch 82/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7112 - val_loss: 0.5668 - val_accuracy: 0.7188\n",
            "Epoch 83/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7091 - val_loss: 0.5802 - val_accuracy: 0.7017\n",
            "Epoch 84/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7145 - val_loss: 0.5695 - val_accuracy: 0.7166\n",
            "Epoch 85/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.7084 - val_loss: 0.5725 - val_accuracy: 0.7209\n",
            "Epoch 86/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7142 - val_loss: 0.5697 - val_accuracy: 0.7137\n",
            "Epoch 87/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7074 - val_loss: 0.5651 - val_accuracy: 0.7181\n",
            "Epoch 88/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7145 - val_loss: 0.5708 - val_accuracy: 0.7093\n",
            "Epoch 89/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.7064 - val_loss: 0.5796 - val_accuracy: 0.7120\n",
            "Epoch 90/100\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5695 - accuracy: 0.7137 - val_loss: 0.5706 - val_accuracy: 0.7154\n",
            "Epoch 91/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.7152 - val_loss: 0.5693 - val_accuracy: 0.7100\n",
            "Epoch 92/100\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7144 - val_loss: 0.5797 - val_accuracy: 0.7017\n",
            "Epoch 93/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7110 - val_loss: 0.5680 - val_accuracy: 0.7141\n",
            "Epoch 94/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7117 - val_loss: 0.5943 - val_accuracy: 0.7007\n",
            "Epoch 95/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7154 - val_loss: 0.5750 - val_accuracy: 0.7085\n",
            "Epoch 96/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7111 - val_loss: 0.5807 - val_accuracy: 0.6943\n",
            "Epoch 97/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7127 - val_loss: 0.5708 - val_accuracy: 0.7067\n",
            "Epoch 98/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7113 - val_loss: 0.5690 - val_accuracy: 0.7114\n",
            "Epoch 99/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7147 - val_loss: 0.5695 - val_accuracy: 0.7090\n",
            "Epoch 100/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7070 - val_loss: 0.5664 - val_accuracy: 0.7111\n",
            "350/350 [==============================] - 0s 874us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.72      0.70      0.71      5610\n",
            "    negative       0.71      0.72      0.71      5590\n",
            "\n",
            "    accuracy                           0.71     11200\n",
            "   macro avg       0.71      0.71      0.71     11200\n",
            "weighted avg       0.71      0.71      0.71     11200\n",
            "\n",
            "Accuracy  : 0.7110714285714286\n",
            "Precision : 0.7111972106360792\n",
            "f1Score : 0.7110384879053454\n",
            "[[3927 1683]\n",
            " [1553 4037]]\n",
            "Results for fold 4\n",
            "Epoch 1/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.7099 - val_loss: 0.5766 - val_accuracy: 0.7162\n",
            "Epoch 2/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7147 - val_loss: 0.5688 - val_accuracy: 0.7186\n",
            "Epoch 3/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7118 - val_loss: 0.5640 - val_accuracy: 0.7214\n",
            "Epoch 4/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7144 - val_loss: 0.5625 - val_accuracy: 0.7190\n",
            "Epoch 5/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7114 - val_loss: 0.5707 - val_accuracy: 0.7121\n",
            "Epoch 6/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7144 - val_loss: 0.5719 - val_accuracy: 0.7083\n",
            "Epoch 7/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7063 - val_loss: 0.5630 - val_accuracy: 0.7203\n",
            "Epoch 8/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.7072 - val_loss: 0.5609 - val_accuracy: 0.7217\n",
            "Epoch 9/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7039 - val_loss: 0.5662 - val_accuracy: 0.7188\n",
            "Epoch 10/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7149 - val_loss: 0.5718 - val_accuracy: 0.7090\n",
            "Epoch 11/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7148 - val_loss: 0.5710 - val_accuracy: 0.7100\n",
            "Epoch 12/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.7171 - val_loss: 0.5602 - val_accuracy: 0.7226\n",
            "Epoch 13/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.7169 - val_loss: 0.5656 - val_accuracy: 0.7143\n",
            "Epoch 14/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7168 - val_loss: 0.5696 - val_accuracy: 0.7135\n",
            "Epoch 15/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7090 - val_loss: 0.5733 - val_accuracy: 0.7178\n",
            "Epoch 16/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7093 - val_loss: 0.5617 - val_accuracy: 0.7206\n",
            "Epoch 17/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7122 - val_loss: 0.5670 - val_accuracy: 0.7183\n",
            "Epoch 18/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7122 - val_loss: 0.5821 - val_accuracy: 0.7017\n",
            "Epoch 19/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7109 - val_loss: 0.5621 - val_accuracy: 0.7201\n",
            "Epoch 20/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7132 - val_loss: 0.5639 - val_accuracy: 0.7200\n",
            "Epoch 21/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.7134 - val_loss: 0.5712 - val_accuracy: 0.7179\n",
            "Epoch 22/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7154 - val_loss: 0.5607 - val_accuracy: 0.7219\n",
            "Epoch 23/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.7133 - val_loss: 0.5601 - val_accuracy: 0.7217\n",
            "Epoch 24/100\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.5659 - accuracy: 0.7144 - val_loss: 0.5860 - val_accuracy: 0.6911\n",
            "Epoch 25/100\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.5657 - accuracy: 0.7158 - val_loss: 0.5786 - val_accuracy: 0.6999\n",
            "Epoch 26/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7154 - val_loss: 0.5637 - val_accuracy: 0.7193\n",
            "Epoch 27/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7181 - val_loss: 0.5603 - val_accuracy: 0.7216\n",
            "Epoch 28/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7175 - val_loss: 0.5608 - val_accuracy: 0.7212\n",
            "Epoch 29/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7165 - val_loss: 0.5635 - val_accuracy: 0.7214\n",
            "Epoch 30/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7108 - val_loss: 0.5917 - val_accuracy: 0.6719\n",
            "Epoch 31/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.7137 - val_loss: 0.5587 - val_accuracy: 0.7226\n",
            "Epoch 32/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7178 - val_loss: 0.5718 - val_accuracy: 0.7223\n",
            "Epoch 33/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.7173 - val_loss: 0.5665 - val_accuracy: 0.7105\n",
            "Epoch 34/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7122 - val_loss: 0.5791 - val_accuracy: 0.7021\n",
            "Epoch 35/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.7135 - val_loss: 0.5792 - val_accuracy: 0.7024\n",
            "Epoch 36/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7095 - val_loss: 0.5646 - val_accuracy: 0.7176\n",
            "Epoch 37/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7135 - val_loss: 0.5779 - val_accuracy: 0.7039\n",
            "Epoch 38/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.7105 - val_loss: 0.5644 - val_accuracy: 0.7224\n",
            "Epoch 39/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7138 - val_loss: 0.5802 - val_accuracy: 0.6978\n",
            "Epoch 40/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.7178 - val_loss: 0.5709 - val_accuracy: 0.7190\n",
            "Epoch 41/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7065 - val_loss: 0.5670 - val_accuracy: 0.7122\n",
            "Epoch 42/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7097 - val_loss: 0.5673 - val_accuracy: 0.7112\n",
            "Epoch 43/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7170 - val_loss: 0.5601 - val_accuracy: 0.7217\n",
            "Epoch 44/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7171 - val_loss: 0.5959 - val_accuracy: 0.6916\n",
            "Epoch 45/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7168 - val_loss: 0.5602 - val_accuracy: 0.7204\n",
            "Epoch 46/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7127 - val_loss: 0.5733 - val_accuracy: 0.7065\n",
            "Epoch 47/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7094 - val_loss: 0.5623 - val_accuracy: 0.7217\n",
            "Epoch 48/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7137 - val_loss: 0.5652 - val_accuracy: 0.7173\n",
            "Epoch 49/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7125 - val_loss: 0.5636 - val_accuracy: 0.7195\n",
            "Epoch 50/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7161 - val_loss: 0.5622 - val_accuracy: 0.7183\n",
            "Epoch 51/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.7148 - val_loss: 0.5617 - val_accuracy: 0.7239\n",
            "Epoch 52/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7145 - val_loss: 0.5634 - val_accuracy: 0.7166\n",
            "Epoch 53/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7160 - val_loss: 0.5633 - val_accuracy: 0.7172\n",
            "Epoch 54/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.7154 - val_loss: 0.5626 - val_accuracy: 0.7169\n",
            "Epoch 55/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7181 - val_loss: 0.5623 - val_accuracy: 0.7217\n",
            "Epoch 56/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5660 - accuracy: 0.7165 - val_loss: 0.5663 - val_accuracy: 0.7149\n",
            "Epoch 57/100\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.5642 - accuracy: 0.7175 - val_loss: 0.5645 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.7119 - val_loss: 0.5668 - val_accuracy: 0.7155\n",
            "Epoch 59/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7148 - val_loss: 0.6207 - val_accuracy: 0.6466\n",
            "Epoch 60/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7133 - val_loss: 0.5658 - val_accuracy: 0.7154\n",
            "Epoch 61/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7045 - val_loss: 0.5668 - val_accuracy: 0.7159\n",
            "Epoch 62/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7164 - val_loss: 0.5820 - val_accuracy: 0.6988\n",
            "Epoch 63/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7059 - val_loss: 0.5594 - val_accuracy: 0.7230\n",
            "Epoch 64/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7184 - val_loss: 0.5660 - val_accuracy: 0.7154\n",
            "Epoch 65/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7186 - val_loss: 0.5657 - val_accuracy: 0.7157\n",
            "Epoch 66/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7176 - val_loss: 0.5603 - val_accuracy: 0.7199\n",
            "Epoch 67/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7124 - val_loss: 0.6051 - val_accuracy: 0.6676\n",
            "Epoch 68/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7114 - val_loss: 0.5758 - val_accuracy: 0.7047\n",
            "Epoch 69/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7131 - val_loss: 0.5640 - val_accuracy: 0.7138\n",
            "Epoch 70/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7149 - val_loss: 0.5705 - val_accuracy: 0.7156\n",
            "Epoch 71/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7197 - val_loss: 0.5620 - val_accuracy: 0.7233\n",
            "Epoch 72/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7100 - val_loss: 0.5628 - val_accuracy: 0.7209\n",
            "Epoch 73/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7090 - val_loss: 0.5678 - val_accuracy: 0.7124\n",
            "Epoch 74/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7154 - val_loss: 0.5676 - val_accuracy: 0.7144\n",
            "Epoch 75/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7156 - val_loss: 0.5579 - val_accuracy: 0.7226\n",
            "Epoch 76/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7166 - val_loss: 0.5604 - val_accuracy: 0.7194\n",
            "Epoch 77/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7129 - val_loss: 0.5649 - val_accuracy: 0.7157\n",
            "Epoch 78/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7134 - val_loss: 0.5671 - val_accuracy: 0.7130\n",
            "Epoch 79/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7190 - val_loss: 0.5608 - val_accuracy: 0.7197\n",
            "Epoch 80/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7164 - val_loss: 0.5657 - val_accuracy: 0.7208\n",
            "Epoch 81/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7164 - val_loss: 0.5647 - val_accuracy: 0.7163\n",
            "Epoch 82/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7165 - val_loss: 0.5645 - val_accuracy: 0.7143\n",
            "Epoch 83/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7159 - val_loss: 0.5666 - val_accuracy: 0.7144\n",
            "Epoch 84/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7161 - val_loss: 0.5644 - val_accuracy: 0.7249\n",
            "Epoch 85/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.7156 - val_loss: 0.5584 - val_accuracy: 0.7237\n",
            "Epoch 86/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7174 - val_loss: 0.5625 - val_accuracy: 0.7238\n",
            "Epoch 87/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5632 - accuracy: 0.7185 - val_loss: 0.5598 - val_accuracy: 0.7209\n",
            "Epoch 88/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7150 - val_loss: 0.5636 - val_accuracy: 0.7174\n",
            "Epoch 89/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.7162 - val_loss: 0.5646 - val_accuracy: 0.7171\n",
            "Epoch 90/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.7119 - val_loss: 0.5688 - val_accuracy: 0.7111\n",
            "Epoch 91/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.7119 - val_loss: 0.5576 - val_accuracy: 0.7231\n",
            "Epoch 92/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7188 - val_loss: 0.5609 - val_accuracy: 0.7224\n",
            "Epoch 93/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7188 - val_loss: 0.5605 - val_accuracy: 0.7208\n",
            "Epoch 94/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7190 - val_loss: 0.5577 - val_accuracy: 0.7229\n",
            "Epoch 95/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7117 - val_loss: 0.5675 - val_accuracy: 0.7148\n",
            "Epoch 96/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7175 - val_loss: 0.5583 - val_accuracy: 0.7211\n",
            "Epoch 97/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7160 - val_loss: 0.5576 - val_accuracy: 0.7248\n",
            "Epoch 98/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7153 - val_loss: 0.5702 - val_accuracy: 0.7081\n",
            "Epoch 99/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7183 - val_loss: 0.5573 - val_accuracy: 0.7246\n",
            "Epoch 100/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7200 - val_loss: 0.5561 - val_accuracy: 0.7250\n",
            "350/350 [==============================] - 0s 918us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.71      0.77      0.74      5616\n",
            "    negative       0.75      0.68      0.71      5584\n",
            "\n",
            "    accuracy                           0.73     11200\n",
            "   macro avg       0.73      0.72      0.72     11200\n",
            "weighted avg       0.73      0.72      0.72     11200\n",
            "\n",
            "Accuracy  : 0.725\n",
            "Precision : 0.7266956485390629\n",
            "f1Score : 0.7244290891475526\n",
            "[[4323 1293]\n",
            " [1787 3797]]\n",
            "Results for fold 5\n",
            "Epoch 1/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7195 - val_loss: 0.5597 - val_accuracy: 0.7273\n",
            "Epoch 2/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.7183 - val_loss: 0.5623 - val_accuracy: 0.7231\n",
            "Epoch 3/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7143 - val_loss: 0.5611 - val_accuracy: 0.7160\n",
            "Epoch 4/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7110 - val_loss: 0.5737 - val_accuracy: 0.7146\n",
            "Epoch 5/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7126 - val_loss: 0.5586 - val_accuracy: 0.7282\n",
            "Epoch 6/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7205 - val_loss: 0.5564 - val_accuracy: 0.7279\n",
            "Epoch 7/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7119 - val_loss: 0.5558 - val_accuracy: 0.7258\n",
            "Epoch 8/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7126 - val_loss: 0.5570 - val_accuracy: 0.7260\n",
            "Epoch 9/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7159 - val_loss: 0.5580 - val_accuracy: 0.7199\n",
            "Epoch 10/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7100 - val_loss: 0.5923 - val_accuracy: 0.6772\n",
            "Epoch 11/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7092 - val_loss: 0.5577 - val_accuracy: 0.7238\n",
            "Epoch 12/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7192 - val_loss: 0.5582 - val_accuracy: 0.7230\n",
            "Epoch 13/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7098 - val_loss: 0.5573 - val_accuracy: 0.7188\n",
            "Epoch 14/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7155 - val_loss: 0.5581 - val_accuracy: 0.7260\n",
            "Epoch 15/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7187 - val_loss: 0.5541 - val_accuracy: 0.7279\n",
            "Epoch 16/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7154 - val_loss: 0.5544 - val_accuracy: 0.7272\n",
            "Epoch 17/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.7152 - val_loss: 0.5719 - val_accuracy: 0.7022\n",
            "Epoch 18/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5647 - accuracy: 0.7149 - val_loss: 0.5697 - val_accuracy: 0.7068\n",
            "Epoch 19/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7183 - val_loss: 0.5664 - val_accuracy: 0.7176\n",
            "Epoch 20/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5622 - accuracy: 0.7178 - val_loss: 0.5621 - val_accuracy: 0.7151\n",
            "Epoch 21/100\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.5619 - accuracy: 0.7191 - val_loss: 0.5626 - val_accuracy: 0.7159\n",
            "Epoch 22/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7203 - val_loss: 0.5602 - val_accuracy: 0.7231\n",
            "Epoch 23/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7183 - val_loss: 0.5948 - val_accuracy: 0.6760\n",
            "Epoch 24/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.7150 - val_loss: 0.5602 - val_accuracy: 0.7162\n",
            "Epoch 25/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.7171 - val_loss: 0.5549 - val_accuracy: 0.7269\n",
            "Epoch 26/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7081 - val_loss: 0.5905 - val_accuracy: 0.6837\n",
            "Epoch 27/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7144 - val_loss: 0.5567 - val_accuracy: 0.7230\n",
            "Epoch 28/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7216 - val_loss: 0.5592 - val_accuracy: 0.7203\n",
            "Epoch 29/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.7149 - val_loss: 0.5553 - val_accuracy: 0.7260\n",
            "Epoch 30/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7184 - val_loss: 0.5562 - val_accuracy: 0.7279\n",
            "Epoch 31/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7194 - val_loss: 0.5555 - val_accuracy: 0.7259\n",
            "Epoch 32/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7155 - val_loss: 0.5685 - val_accuracy: 0.7143\n",
            "Epoch 33/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7172 - val_loss: 0.5556 - val_accuracy: 0.7265\n",
            "Epoch 34/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7135 - val_loss: 0.5565 - val_accuracy: 0.7233\n",
            "Epoch 35/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7129 - val_loss: 0.5683 - val_accuracy: 0.7126\n",
            "Epoch 36/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7142 - val_loss: 0.5659 - val_accuracy: 0.7151\n",
            "Epoch 37/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7190 - val_loss: 0.5657 - val_accuracy: 0.7269\n",
            "Epoch 38/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7175 - val_loss: 0.5701 - val_accuracy: 0.7060\n",
            "Epoch 39/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7171 - val_loss: 0.5560 - val_accuracy: 0.7264\n",
            "Epoch 40/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.7156 - val_loss: 0.5581 - val_accuracy: 0.7249\n",
            "Epoch 41/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7189 - val_loss: 0.5659 - val_accuracy: 0.7152\n",
            "Epoch 42/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7154 - val_loss: 0.5541 - val_accuracy: 0.7254\n",
            "Epoch 43/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7177 - val_loss: 0.5541 - val_accuracy: 0.7250\n",
            "Epoch 44/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7142 - val_loss: 0.5584 - val_accuracy: 0.7229\n",
            "Epoch 45/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7196 - val_loss: 0.5605 - val_accuracy: 0.7208\n",
            "Epoch 46/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7187 - val_loss: 0.5597 - val_accuracy: 0.7184\n",
            "Epoch 47/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7147 - val_loss: 0.5600 - val_accuracy: 0.7260\n",
            "Epoch 48/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7122 - val_loss: 0.5622 - val_accuracy: 0.7198\n",
            "Epoch 49/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5638 - accuracy: 0.7178 - val_loss: 0.5554 - val_accuracy: 0.7224\n",
            "Epoch 50/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.7121 - val_loss: 0.5784 - val_accuracy: 0.7038\n",
            "Epoch 51/100\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.5599 - accuracy: 0.7202 - val_loss: 0.5747 - val_accuracy: 0.7033\n",
            "Epoch 52/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.7181 - val_loss: 0.5545 - val_accuracy: 0.7239\n",
            "Epoch 53/100\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.5601 - accuracy: 0.7207 - val_loss: 0.5574 - val_accuracy: 0.7267\n",
            "Epoch 54/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7169 - val_loss: 0.5609 - val_accuracy: 0.7171\n",
            "Epoch 55/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7167 - val_loss: 0.5609 - val_accuracy: 0.7154\n",
            "Epoch 56/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7196 - val_loss: 0.5571 - val_accuracy: 0.7272\n",
            "Epoch 57/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7205 - val_loss: 0.5553 - val_accuracy: 0.7256\n",
            "Epoch 58/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7105 - val_loss: 0.5690 - val_accuracy: 0.7141\n",
            "Epoch 59/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7177 - val_loss: 0.5604 - val_accuracy: 0.7271\n",
            "Epoch 60/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7152 - val_loss: 0.5548 - val_accuracy: 0.7276\n",
            "Epoch 61/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7201 - val_loss: 0.5867 - val_accuracy: 0.6835\n",
            "Epoch 62/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7063 - val_loss: 0.5682 - val_accuracy: 0.7250\n",
            "Epoch 63/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7200 - val_loss: 0.5536 - val_accuracy: 0.7256\n",
            "Epoch 64/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7148 - val_loss: 0.5681 - val_accuracy: 0.7138\n",
            "Epoch 65/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7159 - val_loss: 0.5588 - val_accuracy: 0.7243\n",
            "Epoch 66/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7169 - val_loss: 0.5552 - val_accuracy: 0.7272\n",
            "Epoch 67/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7102 - val_loss: 0.5602 - val_accuracy: 0.7254\n",
            "Epoch 68/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7190 - val_loss: 0.5543 - val_accuracy: 0.7249\n",
            "Epoch 69/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.7204 - val_loss: 0.5549 - val_accuracy: 0.7250\n",
            "Epoch 70/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7198 - val_loss: 0.5541 - val_accuracy: 0.7277\n",
            "Epoch 71/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7203 - val_loss: 0.5611 - val_accuracy: 0.7154\n",
            "Epoch 72/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7188 - val_loss: 0.5560 - val_accuracy: 0.7246\n",
            "Epoch 73/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.7204 - val_loss: 0.5575 - val_accuracy: 0.7270\n",
            "Epoch 74/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.7147 - val_loss: 0.5574 - val_accuracy: 0.7182\n",
            "Epoch 75/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7172 - val_loss: 0.5610 - val_accuracy: 0.7194\n",
            "Epoch 76/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7173 - val_loss: 0.5562 - val_accuracy: 0.7260\n",
            "Epoch 77/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7204 - val_loss: 0.5572 - val_accuracy: 0.7199\n",
            "Epoch 78/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7147 - val_loss: 0.5647 - val_accuracy: 0.7171\n",
            "Epoch 79/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7175 - val_loss: 0.5592 - val_accuracy: 0.7243\n",
            "Epoch 80/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7163 - val_loss: 0.5639 - val_accuracy: 0.7138\n",
            "Epoch 81/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7170 - val_loss: 0.5724 - val_accuracy: 0.7070\n",
            "Epoch 82/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5635 - accuracy: 0.7142 - val_loss: 0.5533 - val_accuracy: 0.7239\n",
            "Epoch 83/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.7209 - val_loss: 0.5529 - val_accuracy: 0.7285\n",
            "Epoch 84/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5631 - accuracy: 0.7175 - val_loss: 0.5540 - val_accuracy: 0.7277\n",
            "Epoch 85/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7161 - val_loss: 0.5590 - val_accuracy: 0.7287\n",
            "Epoch 86/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.7203 - val_loss: 0.5549 - val_accuracy: 0.7264\n",
            "Epoch 87/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7137 - val_loss: 0.5585 - val_accuracy: 0.7242\n",
            "Epoch 88/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7168 - val_loss: 0.5554 - val_accuracy: 0.7264\n",
            "Epoch 89/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7202 - val_loss: 0.5831 - val_accuracy: 0.6902\n",
            "Epoch 90/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.7160 - val_loss: 0.5800 - val_accuracy: 0.6963\n",
            "Epoch 91/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7194 - val_loss: 0.5531 - val_accuracy: 0.7236\n",
            "Epoch 92/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.7191 - val_loss: 0.5560 - val_accuracy: 0.7273\n",
            "Epoch 93/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7229 - val_loss: 0.5545 - val_accuracy: 0.7237\n",
            "Epoch 94/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7203 - val_loss: 0.5561 - val_accuracy: 0.7204\n",
            "Epoch 95/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7200 - val_loss: 0.5577 - val_accuracy: 0.7222\n",
            "Epoch 96/100\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7181 - val_loss: 0.5701 - val_accuracy: 0.7091\n",
            "Epoch 97/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7126 - val_loss: 0.5541 - val_accuracy: 0.7246\n",
            "Epoch 98/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7183 - val_loss: 0.5559 - val_accuracy: 0.7250\n",
            "Epoch 99/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7209 - val_loss: 0.5540 - val_accuracy: 0.7257\n",
            "Epoch 100/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7167 - val_loss: 0.5590 - val_accuracy: 0.7277\n",
            "350/350 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.71      0.78      0.74      5622\n",
            "    negative       0.75      0.68      0.71      5578\n",
            "\n",
            "    accuracy                           0.73     11200\n",
            "   macro avg       0.73      0.73      0.73     11200\n",
            "weighted avg       0.73      0.73      0.73     11200\n",
            "\n",
            "Accuracy  : 0.7276785714285714\n",
            "Precision : 0.7298883155311247\n",
            "f1Score : 0.7269370426527986\n",
            "[[4378 1244]\n",
            " [1806 3772]]\n"
          ]
        }
      ]
    }
  ]
}